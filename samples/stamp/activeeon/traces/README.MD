# Experimental Settings
This repository demonstrates how to collect traces from different Proactive configurations, generated by CAMP.

`configs` folder contains **three generated Proactive configurations**. Each configuration provides a different dockerized Proactive version:

- **`Config0 (Proactive + HSQLDB)`:** A preconfigured Proactive version that is configured by default to connect to the default HSQLDB database. This is the baseline config used as reference.
- **`Config1 (Proactive + Postgres)`:** A preconfigured Proactive version that is configured to connect to the Postgres database.
- **`Config2 (Proactive + MySQL)`:** A preconfigured Proactive version that is configured to connect to the MySQL database.

The two latter configs are generated using CAMP and the first one is used as baseline or reference.

Since profiling basically takes a snapshot of the running app _n_ times per second (or at _n_ Hz), there is no guarantee it will collect all traces. To increase the quality of the traces, we run the profiler several times, at different frequencies. The selected frequencies are provided in demo.sh script: `FREQS=(15013 16103 17203 18301)`.

The `Dockerfile` for each configuration shows how to instrument Proactive to collect traces at different frequencies. The script `run.sh` is executed for every configuration. It executes the following tasks:
- Run the Proactive server `
/activeeon_enterprise-pca_server-linux-x64-8.5.0-SNAPSHOT/bin/proactive-server &`. The JVM is configured with the options `-XX:+PreserveFramePointer -agentpath:/liblagent.so`
-  Get the corresponding `PID` of the Java process
- Attach the profiler to the Java process `java -cp /libperfagent.jar:$JAVA_HOME/lib/tools.jar net.virtualvoid.perf.AttachOnce $PID`
- Wait until the Proactive server is up `sleep 500`
- Run some tests/load using the proactive client. Here, we send and execute a `workflow-test.xml` in the scheduler `/activeeon_enterprise-pca_server-linux-x64-8.5.0-SNAPSHOT/bin/proactive-client -s /workflow-test.xml`
- We record traces for 300 seconds. The frequency is the default one `perf record -e cpu-clock -p $PID -a -g -o /data/perf.data -- sleep 300`
- We shutdown properly the scheduler using the proactive client.
- We copy traces to the mounted /data folder
> NB: The tested Proactive version being an entreprise version, we do not provide the distribution artifact but in case you need it you can contact fabien.viale@activeeeon.com.
>
An advanced tutorial about docker processes profiling is available here [https://github.com/STAMP-project/docker-traces-xp](https://github.com/STAMP-project/docker-traces-xp). You can check it to get more hints about the used commands.
# Results

Here are the results
```
---- Java traces ----

Configuration 0 contributed 3258/8573 = 38.00 % of all unique traces

Configuration 1 contributed 5916/8573 = 69.00 % of all unique traces

Configuration 2 contributed 3515/8573 = 41.00 % of all unique traces

---- System traces ----

Configuration 0 contributed 1438/3422 = 42.00 % of all unique traces

Configuration 1 contributed 1883/3422 = 55.00 % of all unique traces

Configuration 2 contributed 1575/3422 = 46.00 % of all unique traces
```
-**For Proactive + HSQLDB:**
It contributes to 38.00 % of all unique traces for Java traces and 42.00 % of all unique traces for System traces.

-**For Proactive + Postgres:**
It contributes to 69.00 % of all unique traces for Java traces and 55.00 % of all unique traces for System traces.

-**For Proactive + MySQL:**
It contributes to 41.00 % of all unique traces for Java traces and 46.00 % of all unique traces for System traces.

The traces and raw data are available in the `profiling` folder of each config.

# Conclusion
The three configurations contributed differently to discover unique traces. For Java traces, the CAMP generated configs (Proactive + MySQL and Postgres) discovered more unique traces than the default HSQLDB Proactive configuration (the reference). This shows that the new generated CAMP configs allowed us to discover more JVM traces (which mean more code coverage). For System traces, we obtain the same result as for Java traces with different traces coverage repectively, 42, 55, and 46%. We also remark that PA + Postgres has the most large traces coverage over Java and system traces compared to other configurations.
