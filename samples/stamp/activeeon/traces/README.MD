# Experimental Settings
This repository demonstrates how to collect traces from different Proactive configurations, generated by CAMP.

`configs` folder contains **three generated Proactive configurations**. Each configuration provides a different dockerized Proactive version:

- **`Config0 (Proactive + HSQLDB)`:** A preconfigured Proactive version that is configured by default to connect to the default HSQLDB database. This is the baseline config used as reference.
- **`Config1 (Proactive + Postgres)`:** A preconfigured Proactive version that is configured to connect to the Postgres database. 
- **`Config2 (Proactive + MySQL)`:** A preconfigured Proactive version that is configured to connect to the MySQL database. 

The two latter configs are generated using CAMP and the first one is used as baseline or reference.

The `Dockerfile` for each configuration shows how to instrument Proactive to collect traces. The script `run.sh` is executed for every configuration. It executes the following taks:
- Run the Proactive server `
/activeeon_enterprise-pca_server-linux-x64-8.5.0-SNAPSHOT/bin/proactive-server &`. The JVM is configured with the options `-XX:+PreserveFramePointer -agentpath:/liblagent.so`
-  Get the corresponding `PID` of the Java process
- Attach the profiler to the Java process `java -cp /libperfagent.jar:$JAVA_HOME/lib/tools.jar net.virtualvoid.perf.AttachOnce $PID` 
- Wait until the Proactive server is up `sleep 500` 
- Run some tests/load using the proactive client. Here, we send and execute a `workflow-test.xml` in the schedulrer `/activeeon_enterprise-pca_server-linux-x64-8.5.0-SNAPSHOT/bin/proactive-client -s /workflow-test.xml`
- We record traces for 300 seconds. The frequency is the default one `perf record -e cpu-clock -p $PID -a -g -o /data/perf.data -- sleep 300`
- We shutdown properly the scheduler using the proactive client.
- We copy traces to the mounted /data folder
> NB: The tested Proactive version being an entreprise version, we do not provide the distribution artifact but in case you need it you can contact fabien.viale@activeeeon.com.
> 
An advanced tutorial about docker processes profiling is available here [https://github.com/STAMP-project/docker-traces-xp](https://github.com/STAMP-project/docker-traces-xp). You can check it to get more hints about the used commands. 

# Results

Here are the results
```
---- Java traces ----

Configuration 0 contributed 2190/6255 = 35.00 % of all unique traces

Configuration 1 contributed 2563/6255 = 40.00 % of all unique traces

Configuration 2 contributed 2594/6255 = 41.00 % of all unique traces

---- System traces ----

Configuration 0 contributed 1363/2569 = 53.00 % of all unique traces

Configuration 1 contributed 1238/2569 = 48.00 % of all unique traces

Configuration 2 contributed 1225/2569 = 47.00 % of all unique traces
```
-**For Proactive + HSQLDB:**
It contributes to 35.00 % of all unique traces for Java traces and 53.00 % of all unique traces for System traces.

-**For Proactive + Postgres:**
It contributes to 40.00 % of all unique traces for Java traces and 48.00 % of all unique traces for System traces.

-**For Proactive + MySQL:**
It contributes to 41.00 % of all unique traces for Java traces and 47.00 % of all unique traces for System traces.

The traces and raw data are available in the `profiling` folder of each config.
 
# Conclusion 
The three configurations contributed differently to discover unique traces. For Java traces, the CAMP generated configs (Proactive + MySQL and Postgres) discovered more unique traces than the default HSQLDB Proactive configuration (the reference). This shows that the new generated CAMP configs allowed us to discover more JVM traces (which mean more code coverage). For System traces, we remark that the default Proactive config (the reference) uses more system calls than other generated configs. 
 

